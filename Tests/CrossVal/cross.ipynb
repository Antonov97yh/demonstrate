{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##SVM"
      ],
      "metadata": {
        "id": "8Y7aMziogx65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJc7K8sHE86H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "train = pd.read_csv('train_Mortgage.csv')\n",
        "val = pd.read_csv('val_Mortgage.csv')\n",
        "\n",
        "X_train = train.drop('Mortgage', axis=1)\n",
        "y_train = train['Mortgage']\n",
        "X_val = val.drop('Mortgage', axis=1)\n",
        "y_val = val['Mortgage']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "best_params = {\n",
        "    'C': 1.736433500314599,\n",
        "    'gamma': 0.002869615526354882,\n",
        "    'class_weight': 'balanced',\n",
        "    'kernel': 'rbf',\n",
        "    'probability': True,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model = SVC(**best_params)\n",
        "cv_scores = cross_val_score(model, X_train_scaled, y_train,\n",
        "                          cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "print(f\"Cross-Validation AUC: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n",
        "\n",
        "final_model = SVC(**best_params)\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_proba = final_model.predict_proba(X_val_scaled)[:, 1]\n",
        "val_auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "print(f\"\\nValidation AUC: {val_auc:.4f}\")\n",
        "print(\"\\nModel Parameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param:>15}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua15MkZBKu6X",
        "outputId": "4eeff748-5299-460d-fdd3-6c52c53538a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation AUC: 0.9447 (±0.0057)\n",
            "\n",
            "Validation AUC: 0.9382\n",
            "\n",
            "Model Parameters:\n",
            "              C: 1.736433500314599\n",
            "          gamma: 0.002869615526354882\n",
            "   class_weight: balanced\n",
            "         kernel: rbf\n",
            "    probability: True\n",
            "   random_state: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Pension.csv')\n",
        "val = pd.read_csv('val_Pension.csv')\n",
        "\n",
        "X_train = train.drop('Pension', axis=1)\n",
        "y_train = train['Pension']\n",
        "X_val = val.drop('Pension', axis=1)\n",
        "y_val = val['Pension']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'kernel': 'rbf',\n",
        "        'C': trial.suggest_float('C', 1e-3, 1e3, log=True),\n",
        "        'gamma': trial.suggest_float('gamma', 1e-5, 1e2, log=True),\n",
        "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
        "        'probability': True,\n",
        "        'cache_size': 1000\n",
        "    }\n",
        "\n",
        "    model = SVC(**params)\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train,\n",
        "                           cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "    return np.mean(scores)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "best_params = study.best_params\n",
        "best_params['kernel'] = 'rbf'\n",
        "best_params['probability'] = True\n",
        "\n",
        "final_model_Pension_rbf = SVC(**best_params)\n",
        "final_model_Pension_rbf.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_proba = final_model_Pension_rbf.predict_proba(X_val_scaled)[:, 1]\n",
        "fpr_rbf, tpr_rbf, _ = roc_curve(y_val, y_proba)\n",
        "roc_auc_rbf = roc_auc_score(y_val, y_proba)\n",
        "print(\"\\nOptimization Results:\")\n",
        "print(f\"Best Validation AUC: {roc_auc_rbf:.4f}\")\n",
        "print(\"\\nBest Parameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param:>15}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA7ay-5rMBPG",
        "outputId": "d4d25af8-a186-44c0-dcf4-45d63a9c8a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-30 13:16:03,749] A new study created in memory with name: no-name-16b119f7-74c0-4982-a266-4962ec60f77d\n",
            "[I 2025-03-30 13:18:18,517] Trial 0 finished with value: 0.69277372743284 and parameters: {'C': 268.53759419975336, 'gamma': 0.0007020725739147746, 'class_weight': None}. Best is trial 0 with value: 0.69277372743284.\n",
            "[I 2025-03-30 13:18:35,544] Trial 1 finished with value: 0.7559176973445059 and parameters: {'C': 0.0013987708532579334, 'gamma': 0.0019675451123915013, 'class_weight': None}. Best is trial 1 with value: 0.7559176973445059.\n",
            "[I 2025-03-30 13:18:51,986] Trial 2 finished with value: 0.6594124218979236 and parameters: {'C': 0.02431591428009784, 'gamma': 0.002424498666926584, 'class_weight': None}. Best is trial 1 with value: 0.7559176973445059.\n",
            "[I 2025-03-30 13:19:09,888] Trial 3 finished with value: 0.6850363493523702 and parameters: {'C': 0.010672432999709647, 'gamma': 0.023879066362446872, 'class_weight': None}. Best is trial 1 with value: 0.7559176973445059.\n",
            "[I 2025-03-30 13:19:48,372] Trial 4 finished with value: 0.6499121651944355 and parameters: {'C': 663.3186905608201, 'gamma': 0.2573185569304651, 'class_weight': None}. Best is trial 1 with value: 0.7559176973445059.\n",
            "[I 2025-03-30 13:20:37,189] Trial 5 finished with value: 0.5748072463526881 and parameters: {'C': 16.28519750244021, 'gamma': 16.167128459751968, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.7559176973445059.\n",
            "[I 2025-03-30 13:21:05,999] Trial 6 finished with value: 0.7729314563218755 and parameters: {'C': 63.64953216123634, 'gamma': 5.2633608470946835e-05, 'class_weight': 'balanced'}. Best is trial 6 with value: 0.7729314563218755.\n",
            "[I 2025-03-30 13:21:34,894] Trial 7 finished with value: 0.7729668675663629 and parameters: {'C': 291.6068367874808, 'gamma': 1.540886079081329e-05, 'class_weight': 'balanced'}. Best is trial 7 with value: 0.7729668675663629.\n",
            "[I 2025-03-30 13:22:11,425] Trial 8 finished with value: 0.6848261633583554 and parameters: {'C': 9.027127017093544, 'gamma': 0.001334310432403, 'class_weight': None}. Best is trial 7 with value: 0.7729668675663629.\n",
            "[I 2025-03-30 13:23:02,015] Trial 9 finished with value: 0.5352669064412102 and parameters: {'C': 631.2052174768301, 'gamma': 35.19867432705259, 'class_weight': 'balanced'}. Best is trial 7 with value: 0.7729668675663629.\n",
            "[I 2025-03-30 13:23:41,315] Trial 10 finished with value: 0.7736161349524234 and parameters: {'C': 0.6585585465772417, 'gamma': 1.1241107953330594e-05, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.7736161349524234.\n",
            "[I 2025-03-30 13:24:21,332] Trial 11 finished with value: 0.7736161349524234 and parameters: {'C': 0.5770058255528678, 'gamma': 1.1416514896140643e-05, 'class_weight': 'balanced'}. Best is trial 10 with value: 0.7736161349524234.\n",
            "[I 2025-03-30 13:24:59,416] Trial 12 finished with value: 0.7738197861262245 and parameters: {'C': 0.5937165993386598, 'gamma': 8.979650286976844e-05, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:25:35,624] Trial 13 finished with value: 0.7737119089365744 and parameters: {'C': 0.5499969323012025, 'gamma': 0.00014620289615874986, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:26:14,808] Trial 14 finished with value: 0.7736304335283162 and parameters: {'C': 0.18036380140512212, 'gamma': 0.00018015476999252904, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:26:46,150] Trial 15 finished with value: 0.693217144861809 and parameters: {'C': 3.468368972019767, 'gamma': 0.1887733393762982, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:27:15,853] Trial 16 finished with value: 0.7707737012217907 and parameters: {'C': 0.06966564375055201, 'gamma': 0.013149500142046956, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:27:46,211] Trial 17 finished with value: 0.7735729626825746 and parameters: {'C': 2.3966733037432606, 'gamma': 0.00015999373038010897, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:28:24,454] Trial 18 finished with value: 0.7324219010439087 and parameters: {'C': 0.17803340560007552, 'gamma': 0.32156122628053935, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:29:02,448] Trial 19 finished with value: 0.6027861955257876 and parameters: {'C': 0.0035150077055260786, 'gamma': 4.090642365704054, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:29:31,656] Trial 20 finished with value: 0.7727421429235273 and parameters: {'C': 44.39079698849784, 'gamma': 0.000174273687076239, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:30:11,419] Trial 21 finished with value: 0.7736181368603109 and parameters: {'C': 0.12749559187089454, 'gamma': 0.0001178131610339793, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.7738197861262245.\n",
            "[I 2025-03-30 13:30:46,783] Trial 22 finished with value: 0.7738845102557604 and parameters: {'C': 0.30674757973192535, 'gamma': 0.00044508369810259416, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.7738845102557604.\n",
            "[I 2025-03-30 13:31:16,232] Trial 23 finished with value: 0.7732484492210311 and parameters: {'C': 1.2690572577097314, 'gamma': 0.0005588512923001221, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.7738845102557604.\n",
            "[I 2025-03-30 13:31:48,973] Trial 24 finished with value: 0.7726663473560204 and parameters: {'C': 0.03837679724983078, 'gamma': 0.007410272489650458, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.7738845102557604.\n",
            "[I 2025-03-30 13:32:28,567] Trial 25 finished with value: 0.7736145749659459 and parameters: {'C': 0.3298961985497273, 'gamma': 3.6653399636147006e-05, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.7738845102557604.\n",
            "[I 2025-03-30 13:32:58,410] Trial 26 finished with value: 0.7732395112337503 and parameters: {'C': 1.969305872782657, 'gamma': 0.00037614809743254443, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.7738845102557604.\n",
            "[I 2025-03-30 13:33:27,965] Trial 27 finished with value: 0.7679579784810211 and parameters: {'C': 5.378279593409845, 'gamma': 0.0034890274840831802, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.7738845102557604.\n",
            "[I 2025-03-30 13:34:05,183] Trial 28 finished with value: 0.7547710403907489 and parameters: {'C': 0.02046273260189039, 'gamma': 0.0974484310373669, 'class_weight': 'balanced'}. Best is trial 22 with value: 0.7738845102557604.\n",
            "[I 2025-03-30 13:34:22,732] Trial 29 finished with value: 0.6860928308382667 and parameters: {'C': 0.6118578186653455, 'gamma': 0.0005355503807508273, 'class_weight': None}. Best is trial 22 with value: 0.7738845102557604.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimization Results:\n",
            "Best Validation AUC: 0.7784\n",
            "\n",
            "Best Parameters:\n",
            "              C: 0.30674757973192535\n",
            "          gamma: 0.00044508369810259416\n",
            "   class_weight: balanced\n",
            "         kernel: rbf\n",
            "    probability: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Pension.csv')\n",
        "val = pd.read_csv('val_Pension.csv')\n",
        "\n",
        "X_train = train.drop('Pension', axis=1)\n",
        "y_train = train['Pension']\n",
        "X_val = val.drop('Pension', axis=1)\n",
        "y_val = val['Pension']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "best_params = {\n",
        "    'C': 0.30674757973192535,\n",
        "    'gamma': 0.00044508369810259416,\n",
        "    'class_weight': 'balanced',\n",
        "    'kernel': 'rbf',\n",
        "    'probability': True,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model = SVC(**best_params)\n",
        "cv_scores = cross_val_score(model, X_train_scaled, y_train,\n",
        "                          cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "print(f\"Cross-Validation AUC: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n",
        "\n",
        "final_model = SVC(**best_params)\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_proba = final_model.predict_proba(X_val_scaled)[:, 1]\n",
        "val_auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "print(f\"\\nValidation AUC: {val_auc:.4f}\")\n",
        "print(\"\\nBest Parameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param:>15}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSBGgC4WXADq",
        "outputId": "86af05e7-ec8b-4819-fa82-8f444785b100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation AUC: 0.7739 (±0.0109)\n",
            "\n",
            "Validation AUC: 0.7784\n",
            "\n",
            "Best Parameters:\n",
            "              C: 0.30674757973192535\n",
            "          gamma: 0.00044508369810259416\n",
            "   class_weight: balanced\n",
            "         kernel: rbf\n",
            "    probability: True\n",
            "   random_state: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Savings.csv')\n",
        "val = pd.read_csv('val_Savings.csv')\n",
        "\n",
        "X_train = train.drop('Savings', axis=1)\n",
        "y_train = train['Savings']\n",
        "X_val = val.drop('Savings', axis=1)\n",
        "y_val = val['Savings']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "best_params = {\n",
        "    'C': 11.784268056358108,\n",
        "    'gamma': 0.0005921563846307659,\n",
        "    'class_weight': 'balanced',\n",
        "    'kernel': 'rbf',\n",
        "    'probability': True,\n",
        "    'random_state': 42,\n",
        "    'cache_size': 1000\n",
        "}\n",
        "\n",
        "model = SVC(**best_params)\n",
        "cv_scores = cross_val_score(model, X_train_scaled, y_train,\n",
        "                          cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "\n",
        "print(f\"Cross-Validation AUC: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n",
        "\n",
        "final_model = SVC(**best_params)\n",
        "final_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_proba = final_model.predict_proba(X_val_scaled)[:, 1]\n",
        "val_auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "print(f\"\\nValidation AUC: {val_auc:.4f}\")\n",
        "print(\"\\nBest Parameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param:>15}: {value if not isinstance(value, float) else f'{value:.6f}'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cJzCB6ftOZK",
        "outputId": "6c820d8c-e719-4be1-bf69-ea10c332083a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation AUC: 0.6731 (±0.0115)\n",
            "\n",
            "Validation AUC: 0.6950\n",
            "\n",
            "Best Parameters:\n",
            "              C: 11.784268\n",
            "          gamma: 0.000592\n",
            "   class_weight: balanced\n",
            "         kernel: rbf\n",
            "    probability: True\n",
            "   random_state: 42\n",
            "     cache_size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NLP"
      ],
      "metadata": {
        "id": "wfLAjJ3lg5Vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "train = pd.read_csv('train_Mortgage.csv')\n",
        "val = pd.read_csv('val_Mortgage.csv')\n",
        "\n",
        "X_train = train.drop('Mortgage', axis=1).values\n",
        "y_train = train['Mortgage'].values\n",
        "X_val = val.drop('Mortgage', axis=1).values\n",
        "y_val = val['Mortgage'].values\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "class SimpleMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(X_train.shape[1], 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Обучение базовой модели\n",
        "base_model = SimpleMLP()\n",
        "optimizer = torch.optim.Adam(base_model.parameters(), lr=0.001)\n",
        "loader = DataLoader(TensorDataset(torch.FloatTensor(X_train_scaled), torch.FloatTensor(y_train).unsqueeze(1)),\n",
        "                    batch_size=64, shuffle=True)\n",
        "\n",
        "for _ in range(10):\n",
        "    for Xb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = nn.BCELoss()(base_model(Xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# ROC-AUC до оптимизации\n",
        "base_model.eval()\n",
        "with torch.no_grad():\n",
        "    base_probs = base_model(torch.FloatTensor(X_val_scaled)).numpy().ravel()\n",
        "    base_auc = roc_auc_score(y_val, base_probs)\n",
        "\n",
        "# 3. Оптимизированная модель\n",
        "class OptimizedMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(X_train.shape[1], 48),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.15),\n",
        "            nn.Linear(48, 176),\n",
        "            nn.BatchNorm1d(176),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Dropout(0.57),\n",
        "            nn.Linear(176, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "opt_model = OptimizedMLP()\n",
        "optimizer = torch.optim.RAdam(opt_model.parameters(), lr=0.0005, weight_decay=0.02)\n",
        "loader = DataLoader(TensorDataset(torch.FloatTensor(X_train_scaled), torch.FloatTensor(y_train).unsqueeze(1)),\n",
        "                    batch_size=32, shuffle=True)\n",
        "\n",
        "for _ in range(100):\n",
        "    for Xb, yb in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = nn.BCELoss()(opt_model(Xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "opt_model.eval()\n",
        "with torch.no_grad():\n",
        "    opt_probs = opt_model(torch.FloatTensor(X_val_scaled)).numpy().ravel()\n",
        "    opt_auc = roc_auc_score(y_val, opt_probs)\n",
        "\n",
        "print(f\"Baseline AUC: {base_auc:.4f}\")\n",
        "print(f\"Optimized AUC: {opt_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YueoPtY2g4I_",
        "outputId": "334f7505-17a0-4b4a-fd8a-73f83d263109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline AUC: 0.9391\n",
            "Optimized AUC: 0.9404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train = pd.read_csv('train_Pension.csv')\n",
        "val = pd.read_csv('val_Pension.csv')\n",
        "\n",
        "X_all = pd.concat([train.drop('Pension', axis=1), val.drop('Pension', axis=1)])\n",
        "y_all = pd.concat([train['Pension'], val['Pension']]).values\n",
        "\n",
        "BEST_PARAMS = {\n",
        "    'n_layers': 2,\n",
        "    'activation': 'ELU',\n",
        "    'n_units_0': 400,\n",
        "    'use_bn_0': True,\n",
        "    'dropout_0': 0.266,\n",
        "    'n_units_1': 368,\n",
        "    'use_bn_1': False,\n",
        "    'dropout_1': 0.1297,\n",
        "    'lr': 0.000358,\n",
        "    'batch_size': 16,\n",
        "    'optimizer': 'Adam',\n",
        "    'weight_decay': 0.0341,\n",
        "    'epochs': 14\n",
        "}\n",
        "\n",
        "def create_mlp(input_dim):\n",
        "    layers = []\n",
        "    in_features = input_dim\n",
        "    layers.append(nn.Linear(in_features, 400))\n",
        "    layers.append(nn.ELU())\n",
        "    layers.append(nn.BatchNorm1d(400))\n",
        "    layers.append(nn.Dropout(0.266))\n",
        "\n",
        "    layers.append(nn.Linear(400, 368))\n",
        "    layers.append(nn.ELU())\n",
        "    layers.append(nn.Dropout(0.1297))\n",
        "\n",
        "    layers.append(nn.Linear(368, 1))\n",
        "    layers.append(nn.Sigmoid())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "model = create_mlp(X_train.shape[1])\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                      lr=BEST_PARAMS['lr'],\n",
        "                      weight_decay=BEST_PARAMS['weight_decay'])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(torch.FloatTensor(X_train_scaled),\n",
        "                 torch.FloatTensor(y_train).unsqueeze(1)),\n",
        "    batch_size=16,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "for _ in range(14):\n",
        "    model.train()\n",
        "    for Xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = nn.BCELoss()(model(Xb), yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_probs = model(torch.FloatTensor(X_val_scaled)).numpy().ravel()\n",
        "\n",
        "print(f\"ROC-AUC ДО кросс-валидации: {roc_auc_score(y_val, val_probs):.4f}\")\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "auc_scores = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X_all, y_all)):\n",
        "    X_train, X_test = X_all.iloc[train_idx], X_all.iloc[test_idx]\n",
        "    y_train, y_test = y_all[train_idx], y_all[test_idx]\n",
        "\n",
        "    scaler = StandardScaler().fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    model = create_mlp(X_train.shape[1])\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                          lr=BEST_PARAMS['lr'],\n",
        "                          weight_decay=BEST_PARAMS['weight_decay'])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        TensorDataset(torch.FloatTensor(X_train),\n",
        "                        torch.FloatTensor(y_train).unsqueeze(1)),\n",
        "        batch_size=16,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    for _ in range(14):\n",
        "        model.train()\n",
        "        for Xb, yb in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = nn.BCELoss()(model(Xb), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = model(torch.FloatTensor(X_test)).numpy().ravel()\n",
        "\n",
        "    auc = roc_auc_score(y_test, probs)\n",
        "    auc_scores.append(auc)\n",
        "\n",
        "print(f\"\\nROC-AUC ПОСЛЕ кросс-валидации: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTH_m59dsmk5",
        "outputId": "43c42082-9eb5-453b-87dd-39af019545e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC ДО кросс-валидации: 0.7692\n",
            "\n",
            "ROC-AUC ПОСЛЕ кросс-валидации: 0.7649 ± 0.0198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train_Savings.csv')\n",
        "val_data = pd.read_csv('val_Savings.csv')\n",
        "\n",
        "combined = pd.concat([train_data, val_data])\n",
        "X = combined.drop('Savings', axis=1).values\n",
        "y = combined['Savings'].values\n",
        "\n",
        "X_train = X[:len(train_data)]\n",
        "y_train = y[:len(train_data)]\n",
        "X_val = X[len(train_data):]\n",
        "y_val = y[len(train_data):]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "FIXED_PARAMS = {\n",
        "    'lr': 0.0013819558991985145,\n",
        "    'batch_size': 16,\n",
        "    'optimizer': 'RAdam',\n",
        "    'weight_decay': 0.0056240739754509494,\n",
        "    'architecture': {\n",
        "        'n_layers': 1,\n",
        "        'activation': 'LeakyReLU',\n",
        "        'n_units_0': 352,\n",
        "        'use_bn_0': False,\n",
        "        'dropout_0': 0.4246360943397488\n",
        "    },\n",
        "    'epochs': 30\n",
        "}\n",
        "\n",
        "def create_model(input_size):\n",
        "    layers = []\n",
        "    in_features = input_size\n",
        "\n",
        "    layers.append(nn.Linear(in_features, FIXED_PARAMS['architecture']['n_units_0']))\n",
        "    layers.append(nn.LeakyReLU(negative_slope=0.1))\n",
        "    if FIXED_PARAMS['architecture']['dropout_0'] > 0:\n",
        "        layers.append(nn.Dropout(FIXED_PARAMS['architecture']['dropout_0']))\n",
        "\n",
        "    layers.append(nn.Linear(FIXED_PARAMS['architecture']['n_units_0'], 1))\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "model = create_model(X_train.shape[1])\n",
        "optimizer = getattr(optim, FIXED_PARAMS['optimizer'])(\n",
        "    model.parameters(),\n",
        "    lr=FIXED_PARAMS['lr'],\n",
        "    weight_decay=FIXED_PARAMS['weight_decay']\n",
        ")\n",
        "\n",
        "train_dataset = TensorDataset(\n",
        "    torch.FloatTensor(X_train),\n",
        "    torch.FloatTensor(y_train).reshape(-1, 1)\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=FIXED_PARAMS['batch_size'],\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "for epoch in range(FIXED_PARAMS['epochs']):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = nn.BCELoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_probs = model(torch.FloatTensor(X_val)).numpy().ravel()\n",
        "    auc_raw = roc_auc_score(y_val, val_probs)\n",
        "\n",
        "print(f\"ROC-AUC без кроссвалидации: {auc_raw:.4f}\")\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "auc_scores = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
        "    y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
        "\n",
        "    scaler_fold = StandardScaler().fit(X_train_fold)\n",
        "    X_train_fold = scaler_fold.transform(X_train_fold)\n",
        "    X_test_fold = scaler_fold.transform(X_test_fold)\n",
        "\n",
        "    fold_model = create_model(X_train_fold.shape[1])\n",
        "    fold_optimizer = getattr(optim, FIXED_PARAMS['optimizer'])(\n",
        "        fold_model.parameters(),\n",
        "        lr=FIXED_PARAMS['lr'],\n",
        "        weight_decay=FIXED_PARAMS['weight_decay']\n",
        "    )\n",
        "\n",
        "    fold_loader = DataLoader(\n",
        "        TensorDataset(\n",
        "            torch.FloatTensor(X_train_fold),\n",
        "            torch.FloatTensor(y_train_fold).reshape(-1, 1)\n",
        "        ),\n",
        "        batch_size=FIXED_PARAMS['batch_size'],\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    for epoch in range(FIXED_PARAMS['epochs']):\n",
        "        fold_model.train()\n",
        "        for inputs, labels in fold_loader:\n",
        "            fold_optimizer.zero_grad()\n",
        "            outputs = fold_model(inputs)\n",
        "            loss = nn.BCELoss()(outputs, labels)\n",
        "            loss.backward()\n",
        "            fold_optimizer.step()\n",
        "\n",
        "    fold_model.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = fold_model(torch.FloatTensor(X_test_fold)).numpy().ravel()\n",
        "        auc = roc_auc_score(y_test_fold, probs)\n",
        "        auc_scores.append(auc)\n",
        "\n",
        "print(f\"\\nСредний ROC-AUC с кроссвалидацией: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5CTbREXFYB9",
        "outputId": "395b865b-df54-4d7e-9764-fdc41182e461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC без кроссвалидации: 0.6948\n",
            "\n",
            "Средний ROC-AUC с кроссвалидацией: 0.6727 ± 0.0063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##log_reg"
      ],
      "metadata": {
        "id": "AFiqOaPmJitV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "train = pd.read_csv('train_Pension.csv')\n",
        "val = pd.read_csv('val_Pension.csv')\n",
        "\n",
        "s = 'Pension'\n",
        "\n",
        "X_train = train.drop(columns=[s])\n",
        "y_train = train[s]\n",
        "X_val = val.drop(columns=[s])\n",
        "y_val = val[s]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "FIXED_PARAMS = {\n",
        "    'C': 0.01,\n",
        "    'l1_ratio': 0.8,\n",
        "    'max_iter': 1000,\n",
        "    'penalty': 'elasticnet',\n",
        "    'solver': 'saga',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model = LogisticRegression(**FIXED_PARAMS)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "val_probs = model.predict_proba(X_val_scaled)[:, 1]\n",
        "val_auc = roc_auc_score(y_val, val_probs)\n",
        "\n",
        "print(f\"ROC-AUC без кроссвалидации: {val_auc:.4f}\")\n",
        "\n",
        "X_full_train = pd.concat([X_train, X_test])\n",
        "y_full_train = pd.concat([y_train, y_test])\n",
        "X_full_scaled = scaler.fit_transform(X_full_train)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "auc_scores = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X_full_scaled, y_full_train)):\n",
        "    X_tr, X_te = X_full_scaled[train_idx], X_full_scaled[test_idx]\n",
        "    y_tr, y_te = y_full_train.iloc[train_idx], y_full_train.iloc[test_idx]\n",
        "\n",
        "    fold_model = LogisticRegression(**FIXED_PARAMS)\n",
        "    fold_model.fit(X_tr, y_tr)\n",
        "\n",
        "    fold_probs = fold_model.predict_proba(X_te)[:, 1]\n",
        "    auc = roc_auc_score(y_te, fold_probs)\n",
        "    auc_scores.append(auc)\n",
        "\n",
        "print(f\"\\nСредний ROC-AUC с кроссвалидацией: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "eeFv1oO7JmHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ab0b7d-7535-41ec-ae24-d19da8dc8ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC без кроссвалидации: 0.7778\n",
            "\n",
            "Средний ROC-AUC с кроссвалидацией: 0.7772 ± 0.0039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Savings.csv')\n",
        "val = pd.read_csv('val_Savings.csv')\n",
        "\n",
        "target = 'Savings'\n",
        "\n",
        "X_train = train.drop(columns=[target])\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=[target])\n",
        "y_val = val[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "FIXED_PARAMS = {\n",
        "    'C': 0.1,\n",
        "    'max_iter': 500,\n",
        "    'penalty': 'l2',\n",
        "    'solver': 'lbfgs',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model = LogisticRegression(**FIXED_PARAMS)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "val_probs = model.predict_proba(X_val_scaled)[:, 1]\n",
        "val_auc = roc_auc_score(y_val, val_probs)\n",
        "\n",
        "print(f\"ROC-AUC без кроссвалидации: {val_auc:.4f}\")\n",
        "\n",
        "X_full_train = pd.concat([X_train, X_test])\n",
        "y_full_train = pd.concat([y_train, y_test])\n",
        "X_full_scaled = scaler.fit_transform(X_full_train)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "auc_scores = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X_full_scaled, y_full_train)):\n",
        "    X_tr, X_te = X_full_scaled[train_idx], X_full_scaled[test_idx]\n",
        "    y_tr, y_te = y_full_train.iloc[train_idx], y_full_train.iloc[test_idx]\n",
        "\n",
        "    fold_model = LogisticRegression(**FIXED_PARAMS)\n",
        "    fold_model.fit(X_tr, y_tr)\n",
        "\n",
        "    fold_probs = fold_model.predict_proba(X_te)[:, 1]\n",
        "    auc = roc_auc_score(y_te, fold_probs)\n",
        "    auc_scores.append(auc)\n",
        "\n",
        "print(f\"\\nСредний ROC-AUC с кроссвалидацией: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU39_iVsNdOy",
        "outputId": "99ff8976-6784-4d90-eb6d-25b4045a0af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC без кроссвалидации: 0.6928\n",
            "\n",
            "Средний ROC-AUC с кроссвалидацией: 0.6726 ± 0.0182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Mortgage.csv')\n",
        "val = pd.read_csv('val_Mortgage.csv')\n",
        "\n",
        "target = 'Mortgage'\n",
        "\n",
        "X_train = train.drop(columns=[target])\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=[target])\n",
        "y_val = val[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train,\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "FIXED_PARAMS = {\n",
        "    'C': 0.01,\n",
        "    'l1_ratio': 0.5,\n",
        "    'max_iter': 500,\n",
        "    'penalty': 'elasticnet',\n",
        "    'solver': 'saga',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "model = LogisticRegression(**FIXED_PARAMS)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "val_probs = model.predict_proba(X_val_scaled)[:, 1]\n",
        "val_auc = roc_auc_score(y_val, val_probs)\n",
        "\n",
        "print(f\"ROC-AUC без кроссвалидации: {val_auc:.4f}\")\n",
        "\n",
        "X_full_train = pd.concat([X_train, X_test])\n",
        "y_full_train = pd.concat([y_train, y_test])\n",
        "X_full_scaled = scaler.fit_transform(X_full_train)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "auc_scores = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X_full_scaled, y_full_train)):\n",
        "    X_tr, X_te = X_full_scaled[train_idx], X_full_scaled[test_idx]\n",
        "    y_tr, y_te = y_full_train.iloc[train_idx], y_full_train.iloc[test_idx]\n",
        "\n",
        "    fold_model = LogisticRegression(**FIXED_PARAMS)\n",
        "    fold_model.fit(X_tr, y_tr)\n",
        "\n",
        "    fold_probs = fold_model.predict_proba(X_te)[:, 1]\n",
        "    auc = roc_auc_score(y_te, fold_probs)\n",
        "    auc_scores.append(auc)\n",
        "\n",
        "print(f\"\\nСредний ROC-AUC с кроссвалидацией: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0IyZuy9PTDu",
        "outputId": "a6bf1604-c5f0-4cb6-8cd2-4d9ee57d29d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC-AUC без кроссвалидации: 0.9411\n",
            "\n",
            "Средний ROC-AUC с кроссвалидацией: 0.9451 ± 0.0038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##random forest"
      ],
      "metadata": {
        "id": "8RN0ZfjrQvGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "train_Mortgage = pd.read_csv('train_Mortgage.csv')\n",
        "val_Mortgage = pd.read_csv('val_Mortgage.csv')\n",
        "\n",
        "feature_columns = [col for col in train_Mortgage.columns if col != 'Mortgage']\n",
        "\n",
        "X_train = train_Mortgage[feature_columns]\n",
        "y_train = train_Mortgage['Mortgage']\n",
        "X_val = val_Mortgage[feature_columns]\n",
        "y_val = val_Mortgage['Mortgage']\n",
        "\n",
        "model = ExtraTreesClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=2,\n",
        "    min_samples_split=10,\n",
        "    class_weight=None,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "val_probs = model.predict_proba(X_val)[:, 1]\n",
        "print(f'Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Cross-Validation ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38yzj_76Qu4i",
        "outputId": "79b654b4-1794-43be-8449-3c79ea502d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC-AUC: 0.9409\n",
            "Cross-Validation ROC-AUC: 0.9449 ± 0.0059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Pension = pd.read_csv('train_Pension.csv')\n",
        "val_Pension = pd.read_csv('val_Pension.csv')\n",
        "\n",
        "feature_columns = [col for col in train_Pension.columns if col != 'Pension']\n",
        "\n",
        "X_train = train_Pension[feature_columns]\n",
        "y_train = train_Pension['Pension']\n",
        "X_val = val_Pension[feature_columns]\n",
        "y_val = val_Pension['Pension']\n",
        "\n",
        "model = ExtraTreesClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    min_samples_leaf=2,\n",
        "    min_samples_split=10,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "val_probs = model.predict_proba(X_val)[:, 1]\n",
        "print(f'Pension Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Pension Cross-Validation ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg4Z4qElWlTT",
        "outputId": "0ead761a-1b7a-469d-8121-56e1e9ef0c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pension Validation ROC-AUC: 0.7778\n",
            "Pension Cross-Validation ROC-AUC: 0.7735 ± 0.0103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Savings = pd.read_csv('train_Savings.csv')\n",
        "val_Savings = pd.read_csv('val_Savings.csv')\n",
        "\n",
        "feature_columns = [col for col in train_Savings.columns if col != 'Savings']\n",
        "\n",
        "X_train = train_Savings[feature_columns]\n",
        "y_train = train_Savings['Savings']\n",
        "X_val = val_Savings[feature_columns]\n",
        "y_val = val_Savings['Savings']\n",
        "\n",
        "model = ExtraTreesClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=5,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    class_weight=None,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "val_probs = model.predict_proba(X_val)[:, 1]\n",
        "print(f'Savings Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Savings Cross-Validation ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9dSlrA5Wsfs",
        "outputId": "9523dc48-69c0-4209-838f-4d3dd73765f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Savings Validation ROC-AUC: 0.6921\n",
            "Savings Cross-Validation ROC-AUC: 0.6698 ± 0.0089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Isolation Forest"
      ],
      "metadata": {
        "id": "jWoA6DbKXMWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_Mortgage = pd.read_csv('train_Mortgage.csv')\n",
        "val_Mortgage = pd.read_csv('val_Mortgage.csv')\n",
        "\n",
        "feature_columns = [col for col in train_Mortgage.columns if col != 'Mortgage']\n",
        "X_train = train_Mortgage[feature_columns]\n",
        "y_train = train_Mortgage['Mortgage']\n",
        "X_val = val_Mortgage[feature_columns]\n",
        "y_val = val_Mortgage['Mortgage']\n",
        "\n",
        "anomaly_mortgage_model = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    contamination='auto'\n",
        ")\n",
        "anomaly_mortgage_model.fit(X_train)\n",
        "\n",
        "X_train['is_anomaly'] = anomaly_mortgage_model.predict(X_train)\n",
        "X_train['is_anomaly'] = X_train['is_anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "X_train_isol = X_train[X_train['is_anomaly'] == 0].drop('is_anomaly', axis=1)\n",
        "y_train_isol = y_train[X_train['is_anomaly'] == 0]\n",
        "\n",
        "isol_mortgage_model = RandomForestClassifier(\n",
        "    class_weight=None,\n",
        "    max_depth=10,\n",
        "    min_samples_leaf=2,\n",
        "    min_samples_split=10,\n",
        "    n_estimators=200,\n",
        "    random_state=42\n",
        ")\n",
        "isol_mortgage_model.fit(X_train_isol, y_train_isol)\n",
        "\n",
        "# Функция оценки\n",
        "def evaluate_model(model, X, y):\n",
        "    probs = model.predict_proba(X)[:, 1]\n",
        "    return roc_auc_score(y, probs)\n",
        "\n",
        "# Валидация\n",
        "val_score = evaluate_model(isol_mortgage_model, X_val, y_val)\n",
        "print(f'Mortgage Validation ROC-AUC: {val_score:.4f}')\n",
        "\n",
        "# Кросс-валидация\n",
        "cv_scores = cross_val_score(\n",
        "    isol_mortgage_model,\n",
        "    X_train_isol,\n",
        "    y_train_isol,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Mortgage CV ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrsdhUR1XRdM",
        "outputId": "9dc16fdd-90ac-4441-d622-e8bab7695ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mortgage Validation ROC-AUC: 0.9381\n",
            "Mortgage CV ROC-AUC: 0.9419 ± 0.0052\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "train_Pension = pd.read_csv('train_Pension.csv')\n",
        "val_Pension = pd.read_csv('val_Pension.csv')\n",
        "\n",
        "feature_columns = [col for col in train_Pension.columns if col != 'Pension']\n",
        "X_train = train_Pension[feature_columns]\n",
        "y_train = train_Pension['Pension']\n",
        "X_val = val_Pension[feature_columns]\n",
        "y_val = val_Pension['Pension']\n",
        "\n",
        "anomaly_model = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    contamination='auto'\n",
        ")\n",
        "anomaly_model.fit(X_train)\n",
        "\n",
        "X_train['is_anomaly'] = anomaly_model.predict(X_train)\n",
        "X_train['is_anomaly'] = X_train['is_anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "clean_X = X_train[X_train['is_anomaly'] == 0].drop('is_anomaly', axis=1)\n",
        "clean_y = y_train[X_train['is_anomaly'] == 0]\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    class_weight='balanced',\n",
        "    max_depth=5,\n",
        "    min_samples_leaf=2,\n",
        "    min_samples_split=10,\n",
        "    n_estimators=100,\n",
        "    random_state=42\n",
        ")\n",
        "model.fit(clean_X, clean_y)\n",
        "\n",
        "val_probs = model.predict_proba(X_val)[:, 1]\n",
        "print(f'Pension Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    model,\n",
        "    clean_X,\n",
        "    clean_y,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Pension CV ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MLUFqTAc0n_",
        "outputId": "79071be0-9ecb-42c7-eb85-49ce0f338292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pension Validation ROC-AUC: 0.7727\n",
            "Pension CV ROC-AUC: 0.7639 ± 0.0144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_Savings = pd.read_csv('train_Savings.csv')\n",
        "val_Savings = pd.read_csv('val_Savings.csv')\n",
        "\n",
        "feature_columns = [col for col in train_Savings.columns if col != 'Savings']\n",
        "X_train = train_Savings[feature_columns]\n",
        "y_train = train_Savings['Savings']\n",
        "X_val = val_Savings[feature_columns]\n",
        "y_val = val_Savings['Savings']\n",
        "\n",
        "anomaly_model = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    contamination='auto'\n",
        ")\n",
        "anomaly_model.fit(X_train)\n",
        "\n",
        "X_train['is_anomaly'] = anomaly_model.predict(X_train)\n",
        "X_train['is_anomaly'] = X_train['is_anomaly'].map({1: 0, -1: 1})\n",
        "\n",
        "mask = X_train['is_anomaly'] == 0\n",
        "X_train_clean = X_train[mask].drop('is_anomaly', axis=1)\n",
        "y_train_clean = y_train[mask]\n",
        "\n",
        "savings_model = RandomForestClassifier(\n",
        "    class_weight=None,\n",
        "    max_depth=5,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=2,\n",
        "    n_estimators=300,\n",
        "    random_state=42\n",
        ")\n",
        "savings_model.fit(X_train_clean, y_train_clean)\n",
        "\n",
        "val_probs = savings_model.predict_proba(X_val)[:, 1]\n",
        "print(f'\\nSavings Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    savings_model,\n",
        "    X_train_clean,\n",
        "    y_train_clean,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Savings CV ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrrLqtFTikdi",
        "outputId": "65ad404d-14ed-42bc-d279-1e19307d1554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Savings Validation ROC-AUC: 0.6857\n",
            "Savings CV ROC-AUC: 0.6707 ± 0.0089\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extra Trees"
      ],
      "metadata": {
        "id": "6nyBfMT759mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = [col for col in train_Mortgage.columns if col != 'Mortgage']\n",
        "X_train = train_Mortgage[feature_columns]\n",
        "y_train = train_Mortgage['Mortgage']\n",
        "X_val = val_Mortgage[feature_columns]\n",
        "y_val = val_Mortgage['Mortgage']\n",
        "\n",
        "final_params = {\n",
        "    'n_estimators': 200,\n",
        "    'max_depth': 10,\n",
        "    'min_samples_leaf': 5,\n",
        "    'min_samples_split': 2,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "final_model = ExtraTreesClassifier(**final_params).fit(X_train, y_train)\n",
        "\n",
        "val_probs = final_model.predict_proba(X_val)[:, 1]\n",
        "print(f'Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    final_model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Cross-Validation ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDKJHlP4589C",
        "outputId": "7b4080d6-c74f-452d-8da1-85fd96559cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC-AUC: 0.9402\n",
            "Cross-Validation ROC-AUC: 0.9455 ± 0.0058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = [col for col in train_Pension.columns if col != 'Pension']\n",
        "X_train = train_Pension[feature_columns]\n",
        "y_train = train_Pension['Pension']\n",
        "X_val = val_Pension[feature_columns]\n",
        "y_val = val_Pension['Pension']\n",
        "\n",
        "final_params = {\n",
        "    'n_estimators': 100,\n",
        "    'max_depth': 10,\n",
        "    'min_samples_leaf': 3,\n",
        "    'min_samples_split': 10,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "final_model = ExtraTreesClassifier(**final_params).fit(X_train, y_train)\n",
        "\n",
        "val_probs = final_model.predict_proba(X_val)[:, 1]\n",
        "print(f'Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    final_model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Cross-Validation ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FWEU6wAA7Kg",
        "outputId": "ab5a6ee2-f295-483b-d34c-89173e925070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC-AUC: 0.7781\n",
            "Cross-Validation ROC-AUC: 0.7718 ± 0.0099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = [col for col in train_Savings.columns if col != 'Savings']\n",
        "X_train = train_Savings[feature_columns]\n",
        "y_train = train_Savings['Savings']\n",
        "X_val = val_Savings[feature_columns]\n",
        "y_val = val_Savings['Savings']\n",
        "\n",
        "final_params = {\n",
        "    'n_estimators': 200,\n",
        "    'max_depth': 10,\n",
        "    'min_samples_leaf': 1,\n",
        "    'min_samples_split': 10,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "final_model = ExtraTreesClassifier(**final_params).fit(X_train, y_train)\n",
        "\n",
        "val_probs = final_model.predict_proba(X_val)[:, 1]\n",
        "print(f'Validation ROC-AUC: {roc_auc_score(y_val, val_probs):.4f}')\n",
        "\n",
        "cv_scores = cross_val_score(\n",
        "    final_model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    scoring='roc_auc',\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")\n",
        "print(f'Cross-Validation ROC-AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkJK7meCA_Ay",
        "outputId": "50659126-4d9e-4194-869a-d85f63075204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation ROC-AUC: 0.6891\n",
            "Cross-Validation ROC-AUC: 0.6679 ± 0.0109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##combunation of boosting"
      ],
      "metadata": {
        "id": "c8SoASi5EX4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwo_oZqfVe0",
        "outputId": "db5c172c-0685-421e-ae7a-72d61376c2c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "all_models_m = {\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=839, learning_rate=0.05774795442279825, depth=6,\n",
        "                                  l2_leaf_reg=0.2880865175456189, random_strength=0.16254277485904814,\n",
        "                                  bagging_temperature=0.7992786757360438, border_count=32, verbose=0, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=234, max_depth=14, learning_rate=0.13020051661181956,\n",
        "                            subsample=0.5000183482043092, colsample_bytree=0.9712108470499956,\n",
        "                            min_child_weight=10, gamma=4.927111346239827, reg_alpha=2.3159564553387995,\n",
        "                            reg_lambda=1.7788240357504277, random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(n_estimators=891, learning_rate=0.2775178145806826, num_leaves=154, max_depth=4,\n",
        "                              min_child_samples=5, subsample=0.875834146327149, colsample_bytree=0.9367342318343456,\n",
        "                              reg_alpha=4.0997572412343555, reg_lambda=1.3718029339702882, verbose=-1, random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(max_depth=10, min_samples_leaf=5, min_samples_split=2,\n",
        "                                      n_estimators=200, random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(C=0.01, max_iter=1000, solver='lbfgs', random_state=42)\n",
        "}\n",
        "\n",
        "all_models_p = {\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=200, learning_rate=0.010875325239675968, l2_leaf_reg=0.010817134192675052,\n",
        "                                  random_strength=4.740509717654505, bagging_temperature=0.9584104224319896,\n",
        "                                  border_count=75, depth=1, verbose=0, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=238, max_depth=3, learning_rate=0.058427369161116946,\n",
        "                            subsample=0.9293867219852593, colsample_bytree=0.5238187849054002,\n",
        "                            min_child_weight=6, gamma=4.7308173402905505, reg_alpha=8.066467399907712,\n",
        "                            reg_lambda=4.390801165747763, random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(n_estimators=1191, learning_rate=0.11153678049934727, num_leaves=107, max_depth=3,\n",
        "                              min_child_samples=41, subsample=0.5173705475484477, colsample_bytree=0.7026966245620551,\n",
        "                              reg_alpha=0.45638892145814025, reg_lambda=5.315359029396548, verbose=-1, random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(max_depth=10, min_samples_leaf=3, min_samples_split=10,\n",
        "                                      n_estimators=100, random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(C=0.001, max_iter=1000, solver='lbfgs', random_state=42)\n",
        "}\n",
        "\n",
        "all_models_s = {\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=205, learning_rate=0.041965496183629054, l2_leaf_reg=0.0033091053333706402,\n",
        "                                  random_strength=0.4267643014670958, bagging_temperature=0.6548287821971729,\n",
        "                                  border_count=254, depth=5, verbose=0, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=1446, max_depth=3, learning_rate=0.17633766607373635,\n",
        "                            subsample=0.8802608079409611, colsample_bytree=0.6399123535237496,\n",
        "                            min_child_weight=10, gamma=4.7135127571247475, reg_alpha=7.307229547015628,\n",
        "                            reg_lambda=0.5506026977366328, random_state=42),\n",
        "    \"LightGBM\": LGBMClassifier(n_estimators=903, learning_rate=0.2620735099496511, num_leaves=198, max_depth=5,\n",
        "                              min_child_samples=98, subsample=0.5818744149073714, colsample_bytree=0.9979504029037664,\n",
        "                              reg_alpha=3.2759181752443514, reg_lambda=9.427794042824686, verbose=-1, random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=10,\n",
        "                                      n_estimators=200, random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(C=0.1, max_iter=1000, solver='lbfgs', random_state=42)\n",
        "}\n",
        "\n",
        "def load_data(target):\n",
        "    train = pd.read_csv(f'train_{target}.csv')\n",
        "    val = pd.read_csv(f'val_{target}.csv')\n",
        "\n",
        "    feature_columns = [col for col in train.columns if col != target]\n",
        "    X_train = train[feature_columns]\n",
        "    y_train = train[target]\n",
        "    X_val = val[feature_columns]\n",
        "    y_val = val[target]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "target_config = {\n",
        "    'Mortgage': {\n",
        "        'models': all_models_m,\n",
        "        'combinations': [\n",
        "            'LightGBM+ExtraTrees',\n",
        "            'LightGBM+ExtraTrees+LogisticRegression',\n",
        "            'LightGBM+LogisticRegression',\n",
        "            'LightGBM+XGBoost',\n",
        "            'CatBoost+LightGBM+LogisticRegression',\n",
        "            'LightGBM+XGBoost+LogisticRegression',\n",
        "            'CatBoost+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'LightGBM+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'CatBoost+LightGBM',\n",
        "            'CatBoost+XGBoost+ExtraTrees'\n",
        "        ]\n",
        "    },\n",
        "    'Pension': {\n",
        "        'models': all_models_p,\n",
        "        'combinations': [\n",
        "            'LightGBM+XGBoost+ExtraTrees',\n",
        "            'CatBoost+LightGBM+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'CatBoost+ExtraTrees',\n",
        "            'CatBoost+LightGBM+LogisticRegression',\n",
        "            'CatBoost+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'LightGBM+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'CatBoost+LightGBM+XGBoost+ExtraTrees',\n",
        "            'CatBoost+LightGBM+XGBoost',\n",
        "            'XGBoost+ExtraTrees',\n",
        "            'CatBoost+LightGBM+ExtraTrees+LogisticRegression'\n",
        "        ]\n",
        "    },\n",
        "    'Savings': {\n",
        "        'models': all_models_s,\n",
        "        'combinations': [\n",
        "            'CatBoost+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'CatBoost+XGBoost+LogisticRegression',\n",
        "            'XGBoost+LogisticRegression',\n",
        "            'XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'LightGBM+LogisticRegression',\n",
        "            'LightGBM+XGBoost+LogisticRegression',\n",
        "            'CatBoost+LightGBM+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'ExtraTrees+LogisticRegression',\n",
        "            'LightGBM+XGBoost+ExtraTrees+LogisticRegression',\n",
        "            'CatBoost+LightGBM+XGBoost+LogisticRegression'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "def evaluate_combination(models_dict, combination, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Оценка комбинации моделей\"\"\"\n",
        "    models = combination.split('+')\n",
        "\n",
        "    roc_before = []\n",
        "    for model_name in models:\n",
        "        model = models_dict[model_name]\n",
        "        scores = cross_val_score(model, X_train, y_train,\n",
        "                                scoring='roc_auc', cv=5, n_jobs=-1)\n",
        "        roc_before.append(np.mean(scores))\n",
        "    roc_before = np.mean(roc_before)\n",
        "\n",
        "    stacking = StackingClassifier(\n",
        "        estimators=[(name, models_dict[name]) for name in models],\n",
        "        final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
        "        cv=5,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    stacking.fit(X_train, y_train)\n",
        "    y_proba = stacking.predict_proba(X_val)[:, 1]\n",
        "    roc_after = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "    return roc_before, roc_after\n",
        "\n",
        "results = {}\n",
        "for target in ['Mortgage', 'Pension', 'Savings']:\n",
        "    X_train, y_train, X_val, y_val = load_data(target)\n",
        "    config = target_config[target]\n",
        "\n",
        "    target_results = []\n",
        "    for combo in config['combinations']:\n",
        "        roc_before, roc_after = evaluate_combination(\n",
        "            config['models'], combo,\n",
        "            X_train, y_train, X_val, y_val\n",
        "        )\n",
        "        target_results.append((combo, roc_before, roc_after))\n",
        "\n",
        "    results[target] = target_results\n",
        "\n",
        "for target, data in results.items():\n",
        "    print(f\"\\n**{target}**\")\n",
        "    print(\"```\")\n",
        "    print(\"+---------------------------------------------------------+------------+-----------+\")\n",
        "    print(\"| Комбинация                                              | ROC before | ROC after |\")\n",
        "    print(\"+---------------------------------------------------------+------------+-----------+\")\n",
        "    for combo, before, after in data:\n",
        "        print(f\"| {combo.ljust(55)} | {before:.5f}   | {after:.5f}  |\")\n",
        "    print(\"+---------------------------------------------------------+------------+-----------+\")\n",
        "    print(\"```\\n\")"
      ],
      "metadata": {
        "id": "w1wHFOBvEXXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a937d5-692c-4952-b806-0716f7404e07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**Mortgage**\n",
            "```\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "| Комбинация                                              | ROC before | ROC after |\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "| LightGBM+ExtraTrees                                     | 0.94425   | 0.94315  |\n",
            "| LightGBM+ExtraTrees+LogisticRegression                  | 0.94425   | 0.94312  |\n",
            "| LightGBM+LogisticRegression                             | 0.94362   | 0.94255  |\n",
            "| LightGBM+XGBoost                                        | 0.94525   | 0.94239  |\n",
            "| CatBoost+LightGBM+LogisticRegression                    | 0.94071   | 0.94312  |\n",
            "| LightGBM+XGBoost+LogisticRegression                     | 0.94492   | 0.94235  |\n",
            "| CatBoost+XGBoost+ExtraTrees+LogisticRegression          | 0.94303   | 0.94198  |\n",
            "| LightGBM+XGBoost+ExtraTrees+LogisticRegression          | 0.94506   | 0.94240  |\n",
            "| CatBoost+LightGBM                                       | 0.93894   | 0.94306  |\n",
            "| CatBoost+XGBoost+ExtraTrees                             | 0.94263   | 0.94200  |\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "```\n",
            "\n",
            "\n",
            "**Pension**\n",
            "```\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "| Комбинация                                              | ROC before | ROC after |\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "| LightGBM+XGBoost+ExtraTrees                             | 0.76299   | 0.77949  |\n",
            "| CatBoost+LightGBM+XGBoost+ExtraTrees+LogisticRegression | 0.76768   | 0.77846  |\n",
            "| CatBoost+ExtraTrees                                     | 0.77399   | 0.77819  |\n",
            "| CatBoost+LightGBM+LogisticRegression                    | 0.76381   | 0.77900  |\n",
            "| CatBoost+XGBoost+ExtraTrees+LogisticRegression          | 0.77411   | 0.77824  |\n",
            "| LightGBM+XGBoost+ExtraTrees+LogisticRegression          | 0.76557   | 0.77921  |\n",
            "| CatBoost+LightGBM+XGBoost+ExtraTrees                    | 0.76628   | 0.77871  |\n",
            "| CatBoost+LightGBM+XGBoost                               | 0.76442   | 0.77875  |\n",
            "| XGBoost+ExtraTrees                                      | 0.77350   | 0.77909  |\n",
            "| CatBoost+LightGBM+ExtraTrees+LogisticRegression         | 0.76582   | 0.77886  |\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "```\n",
            "\n",
            "\n",
            "**Savings**\n",
            "```\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "| Комбинация                                              | ROC before | ROC after |\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "| CatBoost+XGBoost+ExtraTrees+LogisticRegression          | 0.67079   | 0.69347  |\n",
            "| CatBoost+XGBoost+LogisticRegression                     | 0.67175   | 0.69343  |\n",
            "| XGBoost+LogisticRegression                              | 0.67375   | 0.69562  |\n",
            "| XGBoost+ExtraTrees+LogisticRegression                   | 0.67180   | 0.69497  |\n",
            "| LightGBM+LogisticRegression                             | 0.64812   | 0.69558  |\n",
            "| LightGBM+XGBoost+LogisticRegression                     | 0.65709   | 0.69553  |\n",
            "| CatBoost+LightGBM+XGBoost+ExtraTrees+LogisticRegression | 0.66139   | 0.69235  |\n",
            "| ExtraTrees+LogisticRegression                           | 0.67018   | 0.69416  |\n",
            "| LightGBM+XGBoost+ExtraTrees+LogisticRegression          | 0.65979   | 0.69466  |\n",
            "| CatBoost+LightGBM+XGBoost+LogisticRegression            | 0.65976   | 0.69242  |\n",
            "+---------------------------------------------------------+------------+-----------+\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Node"
      ],
      "metadata": {
        "id": "PQmIvpsPwMJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH69GmA0FuY3",
        "outputId": "f059b331-8686-483c-ba6b-bca94a50fa2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.4.0->torchdiffeq) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.5.0->torchdiffeq)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m768.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdiffeq\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchdiffeq-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "train_Mortgage = pd.read_csv('train_Mortgage.csv')\n",
        "val_Mortgage = pd.read_csv('val_Mortgage.csv')\n",
        "\n",
        "feature_columns = train_Mortgage.columns.drop(['Mortgage']).tolist()\n",
        "\n",
        "X_train = train_Mortgage[feature_columns]\n",
        "y_train = train_Mortgage[['Mortgage']]\n",
        "X_val = val_Mortgage[feature_columns]\n",
        "y_val = val_Mortgage[['Mortgage']]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)\n",
        "y_val_encoded = le.transform(y_val)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_encoded, dtype=torch.long)\n",
        "y_val_tensor = torch.tensor(y_val_encoded, dtype=torch.long)\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.net(x)\n",
        "\n",
        "class ODEFunc(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            ResBlock(hidden_dim),\n",
        "            ResBlock(hidden_dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class NODEClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.ode_func = ODEFunc(hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        out = torch.relu(self.ode_func(x))\n",
        "        return self.fc2(out)\n",
        "\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "hidden_dim = 64\n",
        "output_dim = len(le.classes_)\n",
        "model = NODEClassifier(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 500\n",
        "\n",
        "val_roc_history = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_preds = torch.argmax(model(X_val_tensor), dim=1)\n",
        "            roc_auc = roc_auc_score(y_val_tensor.numpy(), val_preds.numpy())\n",
        "            val_roc_history.append(roc_auc)\n",
        "\n",
        "roc_without_cv = val_roc_history[-1]\n",
        "\n",
        "full_data = pd.concat([train_Mortgage, val_Mortgage])\n",
        "X_full = full_data[feature_columns]\n",
        "y_full = full_data['Mortgage']\n",
        "y_full_encoded = le.fit_transform(y_full)\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_full, y_full_encoded)):\n",
        "    X_train_fold = X_full.iloc[train_idx]\n",
        "    X_val_fold = X_full.iloc[val_idx]\n",
        "    y_train_fold = y_full_encoded[train_idx]\n",
        "    y_val_fold = y_full_encoded[val_idx]\n",
        "\n",
        "    scaler_fold = StandardScaler()\n",
        "    X_train_sc = scaler_fold.fit_transform(X_train_fold)\n",
        "    X_val_sc = scaler_fold.transform(X_val_fold)\n",
        "\n",
        "    X_train_ts = torch.tensor(X_train_sc, dtype=torch.float32)\n",
        "    X_val_ts = torch.tensor(X_val_sc, dtype=torch.float32)\n",
        "    y_train_ts = torch.tensor(y_train_fold, dtype=torch.long)\n",
        "    y_val_ts = torch.tensor(y_val_fold, dtype=torch.long)\n",
        "\n",
        "    model_cv = NODEClassifier(\n",
        "        input_dim=X_train_sc.shape[1],\n",
        "        hidden_dim=hidden_dim,\n",
        "        output_dim=output_dim\n",
        "    )\n",
        "    optimizer_cv = optim.Adam(model_cv.parameters(), lr=0.01)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model_cv.train()\n",
        "        optimizer_cv.zero_grad()\n",
        "        outputs = model_cv(X_train_ts)\n",
        "        loss = criterion(outputs, y_train_ts)\n",
        "        loss.backward()\n",
        "        optimizer_cv.step()\n",
        "\n",
        "    model_cv.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = torch.argmax(model_cv(X_val_ts), dim=1)\n",
        "        roc_auc = roc_auc_score(y_val_ts.numpy(), preds.numpy())\n",
        "        cv_scores.append(roc_auc)\n",
        "\n",
        "print(f'\\nИтоговые метрики:')\n",
        "print(f'1. ROC-AUC без кроссвалидации: {roc_without_cv:.4f}')\n",
        "print(f'2. Средний ROC-AUC с кроссвалидацией: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1dIYJDOwOKv",
        "outputId": "4fac4bd5-b283-401d-b365-aa3ce87855be"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Итоговые метрики:\n",
            "1. ROC-AUC без кроссвалидации: 0.7477\n",
            "2. Средний ROC-AUC с кроссвалидацией: 0.7857 (±0.0283)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Savings.csv')\n",
        "val = pd.read_csv('val_Savings.csv')\n",
        "feature_columns = train.columns.drop(['Savings']).tolist()\n",
        "\n",
        "X_train = train[feature_columns]\n",
        "y_train = train['Savings']\n",
        "X_val = val[feature_columns]\n",
        "y_val = val['Savings']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "le = LabelEncoder()\n",
        "X_train_sc = scaler.fit_transform(X_train)\n",
        "X_val_sc = scaler.transform(X_val)\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_val_enc = le.transform(y_val)\n",
        "\n",
        "X_train_ts = torch.tensor(X_train_sc, dtype=torch.float32)\n",
        "X_val_ts = torch.tensor(X_val_sc, dtype=torch.float32)\n",
        "y_train_ts = torch.tensor(y_train_enc, dtype=torch.long)\n",
        "y_val_ts = torch.tensor(y_val_enc, dtype=torch.long)\n",
        "\n",
        "model = NODEClassifier(X_train_ts.shape[1], 64, len(le.classes_))\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for _ in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(model(X_train_ts), y_train_ts)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_pred = torch.argmax(model(X_val_ts), dim=1)\n",
        "    roc_without_cv = roc_auc_score(y_val_ts, val_pred)\n",
        "\n",
        "full_data = pd.concat([train, val])\n",
        "X_full = full_data[feature_columns]\n",
        "y_full = le.fit_transform(full_data['Savings'])\n",
        "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "\n",
        "for train_idx, val_idx in kf.split(X_full, y_full):\n",
        "    X_tr, X_vl = X_full.iloc[train_idx], X_full.iloc[val_idx]\n",
        "    y_tr, y_vl = y_full[train_idx], y_full[val_idx]\n",
        "\n",
        "    scaler_cv = StandardScaler()\n",
        "    X_tr_sc = scaler_cv.fit_transform(X_tr)\n",
        "    X_vl_sc = scaler_cv.transform(X_vl)\n",
        "\n",
        "    model_cv = NODEClassifier(X_tr_sc.shape[1], 64, len(le.classes_))\n",
        "    opt = optim.Adam(model_cv.parameters(), lr=0.01)\n",
        "\n",
        "    for _ in range(500):\n",
        "        opt.zero_grad()\n",
        "        loss = criterion(model_cv(torch.tensor(X_tr_sc, dtype=torch.float32)),\n",
        "                       torch.tensor(y_tr, dtype=torch.long))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = torch.argmax(model_cv(torch.tensor(X_vl_sc, dtype=torch.float32)), dim=1)\n",
        "        cv_scores.append(roc_auc_score(y_vl, pred.numpy()))\n",
        "\n",
        "print(f\"Результаты для Savings:\\n\"\n",
        "      f\"1. ROC-AUC без кроссвалидации: {roc_without_cv:.4f}\\n\"\n",
        "      f\"2. ROC-AUC с кроссвалидацией: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7iIKWNFOB4y",
        "outputId": "a87d1eca-517a-4422-ff1f-08fca9db2d60"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты для Savings:\n",
            "1. ROC-AUC без кроссвалидации: 0.5456\n",
            "2. ROC-AUC с кроссвалидацией: 0.5600 (±0.0117)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Pension.csv')\n",
        "val = pd.read_csv('val_Pension.csv')\n",
        "feature_columns = train.columns.drop(['Pension']).tolist()\n",
        "\n",
        "X_train = train[feature_columns]\n",
        "y_train = train['Pension']\n",
        "X_val = val[feature_columns]\n",
        "y_val = val['Pension']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "le = LabelEncoder()\n",
        "X_train_sc = scaler.fit_transform(X_train)\n",
        "X_val_sc = scaler.transform(X_val)\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_val_enc = le.transform(y_val)\n",
        "\n",
        "X_train_ts = torch.tensor(X_train_sc, dtype=torch.float32)\n",
        "X_val_ts = torch.tensor(X_val_sc, dtype=torch.float32)\n",
        "y_train_ts = torch.tensor(y_train_enc, dtype=torch.long)\n",
        "y_val_ts = torch.tensor(y_val_enc, dtype=torch.long)\n",
        "\n",
        "model = NODEClassifier(X_train_ts.shape[1], 64, len(le.classes_))\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for _ in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(model(X_train_ts), y_train_ts)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    val_pred = torch.argmax(model(X_val_ts), dim=1)\n",
        "    roc_without_cv = roc_auc_score(y_val_ts, val_pred)\n",
        "\n",
        "full_data = pd.concat([train, val])\n",
        "X_full = full_data[feature_columns]\n",
        "y_full = le.fit_transform(full_data['Pension'])\n",
        "kf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
        "cv_scores = []\n",
        "\n",
        "for train_idx, val_idx in kf.split(X_full, y_full):\n",
        "    X_tr, X_vl = X_full.iloc[train_idx], X_full.iloc[val_idx]\n",
        "    y_tr, y_vl = y_full[train_idx], y_full[val_idx]\n",
        "\n",
        "    scaler_cv = StandardScaler()\n",
        "    X_tr_sc = scaler_cv.fit_transform(X_tr)\n",
        "    X_vl_sc = scaler_cv.transform(X_vl)\n",
        "\n",
        "    model_cv = NODEClassifier(X_tr_sc.shape[1], 64, len(le.classes_))\n",
        "    opt = optim.Adam(model_cv.parameters(), lr=0.01)\n",
        "\n",
        "    for _ in range(500):\n",
        "        opt.zero_grad()\n",
        "        loss = criterion(model_cv(torch.tensor(X_tr_sc, dtype=torch.float32)),\n",
        "                       torch.tensor(y_tr, dtype=torch.long))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = torch.argmax(model_cv(torch.tensor(X_vl_sc, dtype=torch.float32)), dim=1)\n",
        "        cv_scores.append(roc_auc_score(y_vl, pred.numpy()))\n",
        "\n",
        "print(f\"Результаты для Pension:\\n\"\n",
        "      f\"1. ROC-AUC без кроссвалидации: {roc_without_cv:.4f}\\n\"\n",
        "      f\"2. ROC-AUC с кроссвалидацией: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBFGcmuDPsoy",
        "outputId": "591ca7df-23ca-43f8-ec2e-19c2a95c56bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты для Pension:\n",
            "1. ROC-AUC без кроссвалидации: 0.5957\n",
            "2. ROC-AUC с кроссвалидацией: 0.5860 (±0.0061)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}